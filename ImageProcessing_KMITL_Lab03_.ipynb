{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Acer Aspire 7/Desktop/ImageProcessing/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the VGG16 model\n",
    "model = VGG16()\n",
    "model.summary()\n",
    "kernels, biases = model.layers[1].get_weights()\n",
    "listparam = model.layers[1].get_config()\n",
    "\n",
    "# Load and preprocess the image\n",
    "# image = cv2.imread('./Lab3/image/B.jpeg')\n",
    "image = cv2.imread('./Lab3/image/A.jpg')\n",
    "if image is None:\n",
    "    raise ValueError(\"Failed to load the image.\")\n",
    "\n",
    "img = cv2.resize(image, (224, 224))  # Resize to VGG16 input size\n",
    "img = img_to_array(img)\n",
    "img = expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)\n",
    "\n",
    "# Create a model that outputs the feature maps of the first convolutional layer\n",
    "conv1_layer = model.layers[1]\n",
    "model_conv1 = Model(inputs=model.inputs, outputs=conv1_layer.output)\n",
    "model_conv1.summary()\n",
    "\n",
    "# Extract feature maps\n",
    "feature_maps = model_conv1.predict(img)\n",
    "\n",
    "print('kernel = ', kernels[0][0], '\\nbiases = ', biases)\n",
    "print(listparam)\n",
    "\n",
    "# # Display the original image\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "# plt.title('Original Image')\n",
    "\n",
    "# # Display the preprocessed image\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(img[0])\n",
    "# plt.title('Preprocessed Image')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# Plot the feature maps\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(feature_maps.shape[3]):\n",
    "    plt.subplot(8, 8, i + 1)  # Adjust the subplot layout as needed\n",
    "    plt.imshow(feature_maps[0, :, :, i],cmap='gray' )  # Display a single feature map\n",
    "    plt.axis('off')\n",
    "    plt.title(f'IMG {i + 1}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the VGG16 model (optional, you can load it if you need it)\n",
    "# model = VGG16()\n",
    "# model.summary()\n",
    "# kernels, biases = model.layers[1].get_weights()\n",
    "# listparam = model.layers[1].get_config()\n",
    "\n",
    "\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = cv2.imread('./Lab3/image/B.jpeg')\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB color space\n",
    "\n",
    "\n",
    "\n",
    "image = cv2.resize(image, (224, 224))  # Resize to VGG16 input size\n",
    "\n",
    "rs_image = np.reshape(image,(1,image.shape[0],image.shape[1],image.shape[2]))\n",
    "\n",
    "img_mean = np.array([123.68, 116.779, 103.93])  # Mean pixel values\n",
    "img_mean1 = np.array([103.93, 116.779, 123.68])  # Mean pixel values\n",
    "\n",
    "print (image)\n",
    "# print (img_mean1)\n",
    "# rs_image1 = image - img_mean1  # Subtract mean values\n",
    "# # print (rs_image1)\n",
    "print(\"Preprocessed Image Pixel Values:\")\n",
    "print (rs_image)\n",
    "\n",
    "brg_image = rs_image - img_mean # Subtract mean values\n",
    "print (\"AFTER = \", rs_image)\n",
    "rgb_image1 = rs_image - img_mean1  # Subtract mean values\n",
    "\n",
    "plt.subplot(1, 3, 1)  # 1 row, 2 columns, subplot 1\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 3, 2)  # 1 row, 2 columns, subplot 2\n",
    "plt.imshow(brg_image[0,:,:,:])\n",
    "plt.title('Preprocessed Image')\n",
    "\n",
    "plt.subplot(1, 3, 3)  # 1 row, 2 columns, subplot 2\n",
    "plt.imshow(rgb_image1[0,:,:,:])\n",
    "plt.title('Preprocessed Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "# Load the VGG16 model\n",
    "model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# Load and preprocess the image\n",
    "# image = cv2.imread('./Lab3/image/B.jpeg')\n",
    "image = cv2.imread('./Lab3/image/A.jpg')\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image, (224, 224))\n",
    "img = img_to_array(image)\n",
    "img = expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)\n",
    "\n",
    "# Get the weights (kernels) and biases from the first convolutional layer\n",
    "layer = model.layers[1]\n",
    "kernels, biases = layer.get_weights()\n",
    "\n",
    "# Perform convolution for each color channel and each kernel\n",
    "img_result = np.zeros((1, 224, 224, len(biases)))\n",
    "\n",
    "\n",
    "img_mean = np.array([123.68, 116.779, 103.93])  # Mean pixel values\n",
    "\n",
    "img = img - img_mean # Subtract mean values\n",
    "\n",
    "for i in range(len(biases)):  # Loop over each filter\n",
    "    for channel in range(img.shape[-1]):  # Loop over each color channel\n",
    "        img_result[:, :, :, i] += signal.convolve2d(\n",
    "            img[0, :, :, channel], kernels[:, :, channel, i], mode='same', boundary='fill', fillvalue=0\n",
    "        )\n",
    "\n",
    "# Add the biases to the convolutional results\n",
    "for i in range(len(biases)):\n",
    "    img_result[:, :, :, i] += biases[i]\n",
    "\n",
    "# Apply ReLU activation function\n",
    "img_result[img_result < 0] = 0\n",
    "# img_result[img_result < 8] = 20\n",
    "\n",
    "# Display the result of convolution and ReLU activation (64 feature maps)\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(64):\n",
    "    plt.subplot(8, 8, i + 1)\n",
    "    plt.imshow(img_result[0, :, :, i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'IMG : {i + 1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
